{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **📤 Mount your Google Drive before doing anything!**"
      ],
      "metadata": {
        "id": "JQhFFV2nfdb-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Mount Google Drive\n",
        "\n",
        "# Install Google Drive OCamlfuse\n",
        "!wget -qO google-drive-ocamlfuse.deb https://launchpad.net/~alessandro-strada/+archive/ubuntu/ppa/+files/google-drive-ocamlfuse_0.7.32-0ubuntu5~bpo22.04.1_amd64.deb\n",
        "!sudo DEBIAN_FRONTEND=noninteractive apt-get -qq install ./google-drive-ocamlfuse.deb > /dev/null 2>&1\n",
        "!rm -f google-drive-ocamlfuse.deb\n",
        "!mkdir -p \"/content/drive/MyDrive\"\n",
        "!google-drive-ocamlfuse \"/content/drive/MyDrive\" -headless -id 822900405000-m241g6dhj59ji3sh7b5dfg2vfa2glkid.apps.googleusercontent.com -secret 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"
      ],
      "metadata": {
        "cellView": "form",
        "id": "PCF7Y1ZhhDp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cKdTCuv4tXh"
      },
      "source": [
        "# 🟢 **Welcome to Fakers-Colab!**\n",
        "\n",
        "This is a ported version for Google Colab.\n",
        "\n",
        "\n",
        "# 📝 **-** **Overview**\n",
        "\n",
        "*   Extraction works in full functionality.\n",
        "*   Training can be done without preview.\n",
        "*   Merger works in full functionality.\n",
        "*   You can import/export your workspace using Google Drive.\n",
        "*   Import/export and other manipulations with the workspace can be done in the \"Manage workspace\" block.\n",
        "*   Free runtimes can run for 6-10 hours. Fakers-Colab creates a backup of your workspace while trianing.\n",
        "*   Google doesn't favor long-term heavy calculations. Therefore, if you want to train for more than two sessions in a row, use two Google accounts. It is recommended to split your training across 2 accounts, but you can use one Google Drive account to store your workspace."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuVn21kt40Gw"
      },
      "source": [
        "## 💾 **Install or update from GitLab**\n",
        "\n",
        "* Install or update directly from GitLab.\n",
        "* Requirements are automatically installed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JG-f2WqT4fLK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2af4b39c-a7b5-4862-cf1f-f3cf163920b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'FakersLab'...\n",
            "remote: Enumerating objects: 292, done.\u001b[K\n",
            "remote: Counting objects: 100% (292/292), done.\u001b[K\n",
            "remote: Compressing objects: 100% (246/246), done.\u001b[K\n",
            "remote: Total 292 (delta 30), reused 292 (delta 30), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (292/292), 256.50 MiB | 30.98 MiB/s, done.\n",
            "Resolving deltas: 100% (30/30), done.\n",
            "Updating files: 100% (247/247), done.\n",
            "Collecting numpy==1.23.5\n",
            "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xgboost 2.1.1 requires nvidia-nccl-cu12; platform_system == \"Linux\" and platform_machine != \"aarch64\", which is not installed.\n",
            "albucore 0.0.13 requires numpy<2,>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 1.4.14 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "pandas-stubs 2.1.4.231227 requires numpy>=1.26.0; python_version < \"3.13\", but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "1761f8ee99944306b1fdaaebf6ea2623"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r /content/FakersLab/requirements-colab.txt (line 1)) (4.66.5)\n",
            "Collecting numpy==1.19.3 (from -r /content/FakersLab/requirements-colab.txt (line 2))\n",
            "  Downloading numpy-1.19.3.zip (7.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from -r /content/FakersLab/requirements-colab.txt (line 3)) (2.10.1)\n",
            "Collecting h5py==2.10.0 (from -r /content/FakersLab/requirements-colab.txt (line 4))\n",
            "  Downloading h5py-2.10.0.tar.gz (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.1/301.1 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: Ignored the following yanked versions: 3.4.11.39, 3.4.17.61, 4.4.0.42, 4.4.0.44, 4.5.4.58, 4.5.5.62, 4.7.0.68\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement opencv-python==4.1.0.25 (from versions: 3.4.0.14, 3.4.10.37, 3.4.11.41, 3.4.11.43, 3.4.11.45, 3.4.13.47, 3.4.15.55, 3.4.16.57, 3.4.16.59, 3.4.17.63, 3.4.18.65, 4.3.0.38, 4.4.0.40, 4.4.0.46, 4.5.1.48, 4.5.3.56, 4.5.4.60, 4.5.5.64, 4.6.0.66, 4.7.0.72, 4.8.0.74, 4.8.0.76, 4.8.1.78, 4.9.0.80, 4.10.0.82, 4.10.0.84)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for opencv-python==4.1.0.25\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.23.2)\n",
            "Collecting scikit-image\n",
            "  Downloading scikit_image-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.13.1)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (3.3)\n",
            "Requirement already satisfied: pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.34.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2024.8.10)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (24.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (0.4)\n",
            "Downloading scikit_image-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-image\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.23.2\n",
            "    Uninstalling scikit-image-0.23.2:\n",
            "      Successfully uninstalled scikit-image-0.23.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 1.4.14 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed scikit-image-0.24.0\n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "#@title Install or update from GitLab\n",
        "\n",
        "Mode = \"install\" # @param [\"install\", \"update\", \"remove\"]\n",
        "Branch_name = \"master\" # @param {type:\"string\"}\n",
        "\n",
        "from pathlib import Path\n",
        "if Mode == 'install':\n",
        "  branch_cmd = f\"-b {Branch_name} \" if Branch_name else \"\"\n",
        "  # Clone from GitLab - MedicDoesStuff edition\n",
        "  !git clone {branch_cmd}--depth 1 https://gitlab.com/MedicCodesStuff/FakersLab.git\n",
        "  data = Path(\"/usr/lib/python3.10/multiprocessing/resource_tracker.py\").read_text().replace('if cache:', 'if False:')\n",
        "  Path(\"/usr/lib/python3.10/multiprocessing/resource_tracker.py\").write_text(data)\n",
        "elif Mode == 'update':\n",
        "  %cd /content/FakersLab\n",
        "  !git pull\n",
        "elif Mode == 'remove':\n",
        "  if input(\"Are you sure you want to delete FakersLab folder? (y/n)\").lower().strip() == \"y\":\n",
        "    %cd /content\n",
        "    %rm -r FakersLab/\n",
        "    print(\"Done!\")\n",
        "  else:\n",
        "    print(\"Cancelled...\")\n",
        "\n",
        "if Mode != 'remove':\n",
        "  !pip install numpy==1.23.5\n",
        "  !pip install -r /content/FakersLab/requirements-colab.txt\n",
        "  !pip install --upgrade scikit-image\n",
        "  !pip install colorama\n",
        "  !pip install tensorflow==2.16.2\n",
        "\n",
        "  Path(\"/content/workspace\").mkdir(parents=True, exist_ok=True)\n",
        "  for subdir in [\"data_src\", \"data_src/aligned\", \"data_dst\", \"data_dst/aligned\", \"model\"]:\n",
        "    Path(f\"/content/workspace/{subdir}\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"\\nDone!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqwOlJG4MdLC"
      },
      "source": [
        "## 📁 **Manage workspace**\n",
        "\n",
        "\n",
        "\n",
        "*   You can import/export the workspace or individual data, such as model files, using Google Drive.\n",
        "*   You can clear the entire workspace or delete specific parts of it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "y1Xl_HH2VAiw"
      },
      "outputs": [],
      "source": [
        "#@title Import from Drive\n",
        "\n",
        "Mode = \"workspace\" #@param [\"workspace\", \"data_src\", \"data_dst\", \"data_src aligned\", \"data_dst aligned\", \"models\"]\n",
        "Archive_name = \"workspace.zip\" #@param {type:\"string\"}\n",
        "\n",
        "def zip_and_copy(path, mode):\n",
        "  unzip_cmd=\" -q \"+Archive_name\n",
        "\n",
        "  %cd $path\n",
        "  copy_cmd = \"/content/drive/MyDrive/\"+Archive_name+\" \"+path\n",
        "  print(\"Copying...\")\n",
        "  !cp $copy_cmd\n",
        "  print(\"Unzipping...\")\n",
        "  !unzip $unzip_cmd\n",
        "  !rm $Archive_name\n",
        "\n",
        "if Mode == \"workspace\":\n",
        "  zip_and_copy(\"/content\", \"workspace\")\n",
        "elif Mode == \"data_src\":\n",
        "  zip_and_copy(\"/content/workspace\", \"data_src\")\n",
        "elif Mode == \"data_dst\":\n",
        "  zip_and_copy(\"/content/workspace\", \"data_dst\")\n",
        "elif Mode == \"data_src aligned\":\n",
        "  zip_and_copy(\"/content/workspace/data_src\", \"aligned\")\n",
        "elif Mode == \"data_dst aligned\":\n",
        "  zip_and_copy(\"/content/workspace/data_dst\", \"aligned\")\n",
        "elif Mode == \"models\":\n",
        "  zip_and_copy(\"/content/workspace\", \"model\")\n",
        "\n",
        "print(\"Done!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0Y3WfuwoNXqC"
      },
      "outputs": [],
      "source": [
        "#@title Export to Drive { form-width: \"30%\" }\n",
        "Mode = \"workspace\" #@param [\"workspace\", \"data_src\", \"data_dst\", \"data_src aligned\", \"data_dst aligned\", \"merged\", \"merged_mask\", \"models\", \"result video\", \"result_mask video\"]\n",
        "Archive_name = \"workspace.zip\" #@param {type:\"string\"}\n",
        "\n",
        "def zip_and_copy(path, mode):\n",
        "  zip_cmd=\"-0 -r -q \"+Archive_name+\" \"\n",
        "\n",
        "  %cd $path\n",
        "  zip_cmd+=mode\n",
        "  print(f\"Zipping...\")\n",
        "  !zip $zip_cmd\n",
        "  copy_cmd = \" \"+Archive_name+\"  /content/drive/MyDrive/\"\n",
        "  print(\"Copying...\")\n",
        "  !cp $copy_cmd\n",
        "  !rm $Archive_name\n",
        "\n",
        "if Mode == \"workspace\":\n",
        "  zip_and_copy(\"/content\", \"workspace\")\n",
        "elif Mode == \"data_src\":\n",
        "  zip_and_copy(\"/content/workspace\", \"data_src\")\n",
        "elif Mode == \"data_dst\":\n",
        "  zip_and_copy(\"/content/workspace\", \"data_dst\")\n",
        "elif Mode == \"data_src aligned\":\n",
        "  zip_and_copy(\"/content/workspace/data_src\", \"aligned\")\n",
        "elif Mode == \"data_dst aligned\":\n",
        "  zip_and_copy(\"/content/workspace/data_dst\", \"aligned\")\n",
        "elif Mode == \"merged\":\n",
        "  zip_and_copy(\"/content/workspace/data_dst\", \"merged\")\n",
        "elif Mode == \"merged_mask\":\n",
        "  zip_and_copy(\"/content/workspace/data_dst\", \"merged_mask\")\n",
        "elif Mode == \"models\":\n",
        "  zip_and_copy(\"/content/workspace\", \"model\")\n",
        "elif Mode == \"result video\":\n",
        "  !cp /content/workspace/result.mp4 /content/drive/MyDrive/\n",
        "elif Mode == \"result_mask video\":\n",
        "  !cp /content/workspace/result_mask.mp4 /content/drive/MyDrive/\n",
        "\n",
        "print(\"Done!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Ta6ue_UGMkki"
      },
      "outputs": [],
      "source": [
        "#@title Delete and recreate\n",
        "Mode = \"Delete and recreate workspace\" #@param [\"Delete and recreate workspace\", \"Delete models\", \"Delete data_src\", \"Delete data_src aligned\", \"Delete data_src video\", \"Delete data_dst\", \"Delete data_dst aligned\", \"Delete merged frames\"]\n",
        "\n",
        "%cd \"/content\"\n",
        "\n",
        "if Mode == \"Delete and recreate workspace\":\n",
        "  cmd = \"rm -r /content/workspace ; mkdir /content/workspace; mkdir /content/workspace/data_src; mkdir /content/workspace/data_src/aligned; mkdir /content/workspace/data_dst; mkdir /content/workspace/data_dst/aligned; mkdir /content/workspace/model\"\n",
        "elif Mode == \"Delete models\":\n",
        "  cmd = \"rm -r /content/workspace/model/*\"\n",
        "elif Mode == \"Delete data_src\":\n",
        "  cmd = \"rm /content/workspace/data_src/*.png || rm -r /content/workspace/data_src/*.jpg\"\n",
        "elif Mode == \"Delete data_src aligned\":\n",
        "  cmd = \"rm -r /content/workspace/data_src/aligned/*\"\n",
        "elif Mode == \"Delete data_src video\":\n",
        "  cmd = \"rm -r /content/workspace/data_src.*\"\n",
        "elif Mode == \"Delete data_dst\":\n",
        "  cmd = \"rm /content/workspace/data_dst/*.png || rm /content/workspace/data_dst/*.jpg\"\n",
        "elif Mode == \"Delete data_dst aligned\":\n",
        "  cmd = \"rm -r /content/workspace/data_dst/aligned/*\"\n",
        "elif Mode == \"Delete merged frames\":\n",
        "  cmd = \"rm -r /content/workspace/data_dst/merged; rm -r /content/workspace/data_dst/merged_mask\"\n",
        "\n",
        "answer = input(\"Are you sure you want to \" + Mode + \"? (y/n)\")\n",
        "while answer not in [\"y\", \"n\"]:\n",
        "  print(\"Invalid input\")\n",
        "  answer = input(\"Are you sure you want to \" + Mode + \"? (y/n)\")\n",
        "\n",
        "if answer == \"y\":\n",
        "  !$cmd\n",
        "  print(\"Done!\")\n",
        "else:\n",
        "  print(\"Cancelled...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUNVcbujhm00"
      },
      "source": [
        "## 🛠️ **Extract, sorting and faceset tools**\n",
        "* Extract frames from the source or destination video.\n",
        "* Detect and align faces from frames, with optional debug landmarks.\n",
        "* Export the workspace to Google Drive after extracting and sorting it manually (in the \"Manage workspace\" block).\n",
        "* You can enhance your facesets with the enhancer.\n",
        "* Resize faceset for model compatibility; saves time during training. Keep the original faceset saved on your PC.\n",
        "* Pack or unpack facesets with the packing tool.\n",
        "* Apply or remove a trained XSeg model to the extracted faces.\n",
        "* It is recommended to use the Generic XSeg model for automatic segmentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qwJEbz5Nhot0"
      },
      "outputs": [],
      "source": [
        "#@title Extract frames\n",
        "Video = \"data_src\" #@param [\"data_src\", \"data_dst\"]\n",
        "\n",
        "%cd \"/content\"\n",
        "\n",
        "cmd = \"FakersLab/main.py videoed extract-video\"\n",
        "\n",
        "if Video == \"data_dst\":\n",
        "  cmd+= \" --input-file workspace/data_dst.* --output-dir workspace/data_dst/\"\n",
        "else:\n",
        "  cmd+= \" --input-file workspace/data_src.* --output-dir workspace/data_src/\"\n",
        "\n",
        "!python $cmd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "nmq0Sj2bmq7d"
      },
      "outputs": [],
      "source": [
        "#@title Detect faces\n",
        "Data = \"data_src\" #@param [\"data_src\", \"data_dst\"]\n",
        "Detector = \"S3FD (whole face)\" #@param [\"S3FD\", \"S3FD (whole face)\"]\n",
        "Debug = False #@param {type:\"boolean\"}\n",
        "\n",
        "detect_type = \"s3fd\"\n",
        "dbg = \" --output-debug\" if Debug else \" --no-output-debug\"\n",
        "\n",
        "folder = \"workspace/\"+Data\n",
        "folder_aligned = folder+\"/aligned\"\n",
        "\n",
        "cmd = \"FakersLab/main.py extract --input-dir \"+folder+\" --output-dir \"+folder_aligned\n",
        "cmd+=\" --detector \"+detect_type+\" --force-gpu-idxs 0\"+dbg\n",
        "\n",
        "if \"whole face\" in Detector:\n",
        "  cmd+=\" --face-type whole_face\"\n",
        "%cd \"/content\"\n",
        "!python $cmd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TRNxUFE6p6Eu"
      },
      "outputs": [],
      "source": [
        "#@title Sort aligned\n",
        "Data = \"data_src\" #@param [\"data_src\", \"data_dst\"]\n",
        "sort_type = \"hist\" #@param [\"blur\", \"motion-blur\", \"face-yaw\", \"face-pitch\", \"face-source-rect-size\", \"hist\", \"hist-dissim\", \"brightness\", \"hue\", \"black\", \"origname\", \"oneface\", \"final-by-blur\", \"final-by-size\", \"absdiff\", \"final\", \"final-fast\"]\n",
        "\n",
        "cmd = \"FakersLab/main.py sort --input-dir workspace/\"+Data+\"/aligned --by \"+sort_type\n",
        "\n",
        "%cd \"/content\"\n",
        "!python $cmd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "O5MbnVDyXkP7"
      },
      "outputs": [],
      "source": [
        "#@title Faceset Enhancer\n",
        "Data = \"data_src\" #@param [\"data_src\", \"data_dst\"]\n",
        "\n",
        "data_path = \"/content/workspace/\"+Data+\"/aligned\"\n",
        "cmd = \"/content/FakersLab/main.py facesettool enhance --input-dir \"+data_path\n",
        "!python $cmd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Hyg5SREuMx8Q"
      },
      "outputs": [],
      "source": [
        "#@title Resize faceset\n",
        "Data = \"data_src\" #@param [\"data_src\", \"data_dst\"]\n",
        "\n",
        "cmd = \"/content/FakersLab/main.py facesettool resize --input-dir /content/workspace/\" + \\\n",
        "      f\"{Data}/aligned\"\n",
        "\n",
        "!python $cmd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ypLfPUNHZNEp"
      },
      "outputs": [],
      "source": [
        "#@title Pack/Unpack aligned faceset\n",
        "\n",
        "Folder = \"data_src\" #@param [\"data_src\", \"data_dst\"]\n",
        "Mode = \"unpack\" #@param [\"pack\", \"unpack\"]\n",
        "\n",
        "cmd = \"/content/FakersLab/main.py util --input-dir /content/workspace/\" + \\\n",
        "      f\"{Folder}/aligned --{Mode}-faceset\"\n",
        "\n",
        "!python $cmd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-VVvtoBMGnrA"
      },
      "outputs": [],
      "source": [
        "#@title Apply or remove XSeg mask to the faces\n",
        "Mode = \"Apply mask\" # @param [\"Apply mask\", \"Remove mask\"]\n",
        "Data = \"data_src\" # @param [\"data_src\", \"data_dst\"]\n",
        "GenericXSeg = True # @param {type:\"boolean\"}\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "mode_arg = 'apply' if Mode == \"Apply mask\" else 'remove'\n",
        "\n",
        "if GenericXSeg:\n",
        "    xseg_path = Path('/content/GenericXSeg')\n",
        "    if not xseg_path.exists():\n",
        "        print('Downloading Generic XSeg model ...')\n",
        "        xseg_url = 'https://huggingface.co/medicreal/FL-Dependencies/resolve/main/model_generic_xseg.zip?download=true'\n",
        "        xseg_path.mkdir(parents=True)\n",
        "        !wget -q --no-check-certificate $xseg_url -O /content/GenericXSeg.zip\n",
        "        !unzip -q /content/GenericXSeg.zip -d /content/GenericXSeg/\n",
        "        !rm /content/GenericXSeg.zip\n",
        "\n",
        "main_path = '/content/FakersLab/main.py'\n",
        "data_path = f'/content/workspace/{Data}/aligned'\n",
        "model_path = '/content/workspace/model' if not GenericXSeg else str(xseg_path)\n",
        "\n",
        "cmd = f'python {main_path} xseg {mode_arg} --input-dir {data_path} '\n",
        "cmd += f'--model-dir {model_path}' if mode_arg == 'apply' else ''\n",
        "\n",
        "!$cmd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTuyUxgdLA13"
      },
      "source": [
        "## 🤖 **Train model**\n",
        "\n",
        "* Choose your model type, but SAEHD is recommended for everyone.\n",
        "* Set model options in the output field.\n",
        "* You can manually preview by going to the model folder in the file manager and double-clicking on the PNG files.\n",
        "* Your workspace will be archived and uploaded to the mounted Drive after 11 hours from the start of the session.\n",
        "* If you select the \"Backup_every_hour\" option, your workspace will be backed up every hour.\n",
        "* You can also manually export your workspace in the \"Manage workspace\" block.\n",
        "* The \"Silent_Start\" option automatically starts with the best GPU and the last model you used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "E3MeOt_5Fbaz"
      },
      "outputs": [],
      "source": [
        "#@title Uptime\n",
        "import psutil, os, time\n",
        "\n",
        "p = psutil.Process(os.getpid())\n",
        "uptime = time.time() - p.create_time()\n",
        "print(f'Session in running from {int(uptime / 3600)} hours')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "cellView": "form",
        "id": "k-ya_slpU9mZ",
        "outputId": "a243e9a6-8215-4776-ec62-0d7e4908e203",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Time to backup: 11 hours\n",
            "                                                               #####                                                                                       .##############*                                                                                      ###############(###                                                               **           ##*#########/(############                                                            /&&&&%*      ######### ##   (# #######                                                              /&&&&&&&&&/, (####### #       #*######                                                              *&&&&&&&&&&&&&#/#####.#(      # #########                                                           *&&&&&&&&&&&&&%%%%%((## /#### ##########                                                     ###    *&%%%%%%%%&&&&%%%%%%%%%#(###########                                                     ########(##(%%%%%%%%&&&&&&&&&&&%%%%%%%#(######.                                                     /##########(%%%%%%%%%%%&&%%%%&&&%%%%%&&&&%%(#*                                                       ##########(%%%%%%%%%%%%%%%%%%&&&&&&&&&&&&#.                                                   ##. ###########(/&&&&%%%%%%%%%%%%%%%&&&&&&&/                                                       ############# (##/&&&&%%&%%%%%%%%%&&&&&%*                                                          .############ #   *&&&&&&%%&%%%%%%%%(,                                                               *########## ##   *&&&&&&&%&%%%%(#####(                                                                  ######## #   *&&&&&&%%#(###########                                                                 ######### ###*&&&&#( #############,                                                              ################  .  ###########                                                                     #############################(                                                                        ###  *######################                                                                                ####################.                                                                              *#######*      ###                                                  \n",
            "You are using Machine Video Editor community fork\n",
            "Join us in discord, invite link https://discord.gg/KBQB8x9K5c\n",
            "Commercial inquires send to ognjen@syntheticfactory.com (shared with the group)\n",
            "Support us via donation https://www.paypal.me/ognjenjaric or patreon https://www.patreon.com/machineeditor\n",
            "If you would like to contribute we are looking for more members, apply via discord!\n",
            "\n",
            "Running trainer.\n",
            "\n",
            "Silent start: choosed model \"288nomask\"\n",
            "Loading 288nomask_AMP model...\n",
            "Silent start: choosed device Tesla T4\n",
            "Initializing models: 100% 7/7 [00:19<00:00,  2.80s/it]\n",
            "Loaded 8297 packed faces from /content/workspace/data_src/aligned\n",
            "Sort by yaw: 100% 128/128 [00:00<00:00, 226.59it/s]\n",
            "Sort by yaw: 100% 128/128 [00:00<00:00, 225.99it/s]\n",
            "============= Model Summary ==============\n",
            "==                                      ==\n",
            "==            Model name: 288nomask_AMP ==\n",
            "==                                      ==\n",
            "==     Current iteration: 952057        ==\n",
            "==                                      ==\n",
            "==----------- Model Options ------------==\n",
            "==                                      ==\n",
            "==    retraining_samples: False         ==\n",
            "==            resolution: 288           ==\n",
            "==             face_type: wf            ==\n",
            "==     models_opt_on_gpu: True          ==\n",
            "==               ae_dims: 288           ==\n",
            "==            inter_dims: 1024          ==\n",
            "==                e_dims: 72            ==\n",
            "==                d_dims: 72            ==\n",
            "==           d_mask_dims: 22            ==\n",
            "==          morph_factor: 0.5           ==\n",
            "==       masked_training: True          ==\n",
            "==             eyes_prio: False         ==\n",
            "==            mouth_prio: False         ==\n",
            "==           uniform_yaw: True          ==\n",
            "==         loss_function: SSIM          ==\n",
            "==         blur_out_mask: True          ==\n",
            "==             adabelief: True          ==\n",
            "==            lr_dropout: y             ==\n",
            "==           random_warp: False         ==\n",
            "==      random_hsv_power: 0.0           ==\n",
            "==     random_downsample: False         ==\n",
            "==          random_noise: False         ==\n",
            "==           random_blur: False         ==\n",
            "==           random_jpeg: False         ==\n",
            "==         random_shadow: none          ==\n",
            "==      background_power: 0.0           ==\n",
            "==               ct_mode: none          ==\n",
            "==          random_color: False         ==\n",
            "==              clipgrad: True          ==\n",
            "==              use_fp16: False         ==\n",
            "==               cpu_cap: 8             ==\n",
            "==       preview_samples: 4             ==\n",
            "==    force_full_preview: False         ==\n",
            "==                    lr: 2e-05         ==\n",
            "==       autobackup_hour: 0             ==\n",
            "==          session_name: super idol    ==\n",
            "==     maximum_n_backups: 24            ==\n",
            "== write_preview_history: False         ==\n",
            "==           target_iter: 0             ==\n",
            "==       random_src_flip: False         ==\n",
            "==       random_dst_flip: False         ==\n",
            "==            batch_size: 4             ==\n",
            "==             gan_power: 0.1           ==\n",
            "==        gan_patch_size: 40            ==\n",
            "==              gan_dims: 16            ==\n",
            "==         gan_smoothing: 0.3           ==\n",
            "==             gan_noise: 0.06          ==\n",
            "==            preview_mf: 1             ==\n",
            "==                                      ==\n",
            "==------------- Running On -------------==\n",
            "==                                      ==\n",
            "==          Device index: 0             ==\n",
            "==                  Name: Tesla T4      ==\n",
            "==                  VRAM: 13.62GB       ==\n",
            "==                                      ==\n",
            "==========================================\n",
            "Starting. Press \"Enter\" to stop training and save model.\n",
            "[06:41:09][#952780][1256ms][0.3965][0.2864]Process Process-5:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/content/FakersLab/models/ModelBase.py\", line 884, in process\n",
            "    time.sleep(0.01)\n",
            "KeyboardInterrupt\n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "#@title Training\n",
        "Model = \"SAEHD\" #@param [\"SAEHD\", \"AMP\", \"AMPLegacy\", \"Quick96\", \"XSeg\"]\n",
        "Train_only_src = False #@param {type:\"boolean\"}\n",
        "Archive_name_backup = \"workspace.zip\" #@param {type:\"string\"}\n",
        "Pretraining_dataset_path = '/content/pretrain/' #@param {type:\"string\"}\n",
        "Export_model_only = False #@param {type:\"boolean\"}\n",
        "Backup_every_specified_time = True #@param {type:\"boolean\"}\n",
        "backup_time = 1 #@param {type:\"number\"}\n",
        "Silent_Start = True #@param {type:\"boolean\"}\n",
        "\n",
        "%cd \"/content\"\n",
        "\n",
        "import psutil, os, time\n",
        "\n",
        "p = psutil.Process(os.getpid())\n",
        "uptime = time.time() - p.create_time()\n",
        "\n",
        "if Export_model_only:\n",
        "  if os.path.exists(Archive_name_backup) and not os.path.exists(Archive_name_backup.replace('.zip', '_model.zip')):\n",
        "    os.system(f\"rm {Archive_name_backup}\")\n",
        "    print('Full workspace archive deleted\\nCreating model archive...')\n",
        "    os.system('zip -0 -r -q '+Archive_name_backup.replace('.zip', '_model.zip')+' workspace/model')\n",
        "    print(\"Archive created!\")\n",
        "  elif not os.path.exists(Archive_name_backup) and not os.path.exists(Archive_name_backup.replace('.zip', '_model.zip')):\n",
        "    print('Creating model archive...')\n",
        "    os.system('zip -0 -r -q '+Archive_name_backup.replace('.zip', '_model.zip')+' workspace/model')\n",
        "  else:\n",
        "    print('Archive exists')\n",
        "\n",
        "\n",
        "if Backup_every_specified_time and not Export_model_only:\n",
        "  if not os.path.exists(Archive_name_backup):\n",
        "    if os.path.exists(Archive_name_backup.replace('.zip', '_model.zip')):\n",
        "      print('Removing model archive...')\n",
        "      os.system(f\"rm {Archive_name_backup.replace('.zip', '_model.zip')}\")\n",
        "    print(\"Creating workspace archive ...\")\n",
        "    os.system('zip -0 -r -q '+Archive_name_backup+' workspace')\n",
        "    print(\"Archive created!\")\n",
        "  else:\n",
        "    print(\"Archive exists!\")\n",
        "\n",
        "if Backup_every_specified_time:\n",
        "  print(\"Time to end session: \"+str(round((43200-uptime)/3600))+\" hours\")\n",
        "  backup_time = str(backup_time * 3600)\n",
        "  if not Export_model_only:\n",
        "    backup_cmd = \" --execute-program -\"+backup_time+\" \\\"import os; os.system('zip -0 -r -q \"+Archive_name_backup+\" workspace/model'); os.system('cp /content/\"+Archive_name_backup+\" /content/drive/MyDrive/'); print('Backed up!') \\\"\"\n",
        "  else:\n",
        "    backup_cmd = \" --execute-program -\"+backup_time+\" \\\"import os; os.system('zip -0 -r -q \"+Archive_name_backup.replace('.zip', '_model.zip')+\" workspace/model'); os.system('cp /content/\"+Archive_name_backup.replace('.zip', '_model.zip') +\" /content/drive/My\\ Drive/'); print('Backed up!') \\\"\"\n",
        "elif (round(39600-uptime) > 0):\n",
        "  print(\"Time to backup: \"+str(round((39600-uptime)/3600))+\" hours\")\n",
        "  backup_time = str(round(39600-uptime))\n",
        "  if not Export_model_only:\n",
        "    backup_cmd = \" --execute-program -\"+backup_time+\" \\\"import os; os.system('zip -0 -r -q \"+Archive_name_backup+\" workspace'); os.system('cp /content/\"+Archive_name_backup+\" /content/drive/MyDrive/'); print('Backed up!') \\\"\"\n",
        "  else:\n",
        "    backup_cmd = \" --execute-program -\"+backup_time+\" \\\"import os; os.system('zip -0 -r -q \"+Archive_name_backup.replace('.zip', '_model.zip')+\" workspace/model'); os.system('cp /content/\"+Archive_name_backup.replace('.zip', '_model.zip') +\" /content/drive/My\\ Drive/'); print('Backed up!') \\\"\"\n",
        "else:\n",
        "  print(\"Session expires in less than an hour.\")\n",
        "  backup_cmd = \"\"\n",
        "\n",
        "if Train_only_src:\n",
        "  if Model not in [\"AMP\", \"AMPLegacy\"]:\n",
        "    answer = ''\n",
        "    print('The src-src training is only for AMP model. Do you want to continue anyway? (y/n)')\n",
        "    while True:\n",
        "      answer = input()\n",
        "      if answer == 'y':\n",
        "        cmd = \"FakersLab/main.py train --training-data-src-dir workspace/data_src/aligned --training-data-dst-dir workspace/data_src/aligned --pretraining-data-dir \" + Pretraining_dataset_path + \" --model-dir workspace/model --model \"+Model\n",
        "      elif answer == 'n':\n",
        "        cmd = \"FakersLab/main.py train --training-data-src-dir workspace/data_src/aligned --training-data-dst-dir workspace/data_dst/aligned --pretraining-data-dir \" + Pretraining_dataset_path + \" --model-dir workspace/model --model \"+Model\n",
        "      else:\n",
        "        print('Wrong value! Insert y or n:')\n",
        "      if answer in ['y', 'n']:\n",
        "        break\n",
        "  else:\n",
        "    cmd = \"FakersLab/main.py train --training-data-src-dir workspace/data_src/aligned --training-data-dst-dir workspace/data_src/aligned --pretraining-data-dir \" + Pretraining_dataset_path + \" --model-dir workspace/model --model \"+Model\n",
        "else:\n",
        "  cmd = \"FakersLab/main.py train --training-data-src-dir workspace/data_src/aligned --training-data-dst-dir workspace/data_dst/aligned --pretraining-data-dir \" + Pretraining_dataset_path + \" --model-dir workspace/model --model \"+Model\n",
        "\n",
        "if Model == \"Quick96\":\n",
        "  cmd += \" --pretrained-model-dir pretrain_Q96\"\n",
        "\n",
        "if Silent_Start:\n",
        "  cmd += \" --silent-start\"\n",
        "\n",
        "if (backup_cmd != \"\"):\n",
        "  train_cmd = (cmd+backup_cmd)\n",
        "else:\n",
        "  train_cmd = (cmd)\n",
        "\n",
        "!python $train_cmd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://images.gmanews.tv/webpics/2024/07/Alice_Guo_with_lawyer_2024_07_15_21_32_07.jpg"
      ],
      "metadata": {
        "id": "YSxM5bij92ON",
        "outputId": "19b0ae33-d580-4ace-c173-df0dafa2e5f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-23 06:41:57--  https://images.gmanews.tv/webpics/2024/07/Alice_Guo_with_lawyer_2024_07_15_21_32_07.jpg\n",
            "Resolving images.gmanews.tv (images.gmanews.tv)... 54.230.176.109, 54.230.176.79, 54.230.176.59, ...\n",
            "Connecting to images.gmanews.tv (images.gmanews.tv)|54.230.176.109|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 48921 (48K) [image/jpeg]\n",
            "Saving to: ‘Alice_Guo_with_lawyer_2024_07_15_21_32_07.jpg’\n",
            "\n",
            "Alice_Guo_with_lawy 100%[===================>]  47.77K   287KB/s    in 0.2s    \n",
            "\n",
            "2024-08-23 06:41:59 (287 KB/s) - ‘Alice_Guo_with_lawyer_2024_07_15_21_32_07.jpg’ saved [48921/48921]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colorama"
      ],
      "metadata": {
        "id": "Kbzoqz0-2GPM",
        "outputId": "01c3bcc4-26a3-4176-c335-b7bfd8d74d86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: colorama\n",
            "Successfully installed colorama-0.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avAcSL_uvtq_"
      },
      "source": [
        "## ⚪ **Merge frames**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "A3Y8K22Sv9Gn"
      },
      "outputs": [],
      "source": [
        "#@title Merge\n",
        "Model = \"AMP\" #@param [\"SAEHD\", \"AMP\", \"Quick96\"]\n",
        "\n",
        "cmd = \"FakersLab/main.py merge --input-dir workspace/data_dst --output-dir workspace/data_dst/merged --output-mask-dir workspace/data_dst/merged_mask --aligned-dir workspace/data_dst/aligned --model-dir workspace/model --model \"+Model\n",
        "\n",
        "%cd \"/content\"\n",
        "!python $cmd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "JNeGfiZpxlnz"
      },
      "outputs": [],
      "source": [
        "#@title Get result video\n",
        "Mode = \"result video\" #@param [\"result video\", \"result_mask video\"]\n",
        "Bitrate = 24 #@param {type:\"integer\"}\n",
        "Copy_to_Drive = True #@param {type:\"boolean\"}\n",
        "\n",
        "cmd = \"FakersLab/main.py videoed video-from-sequence --input-dir workspace/data_dst/merged --output-file workspace/result.mp4 --reference-file workspace/data_dst.mp4 --include-audio --bitrate \" + str(Bitrate)\n",
        "cmd_mask = \"FakersLab/main.py videoed video-from-sequence --input-dir workspace/data_dst/merged_mask --output-file workspace/result_mask.mp4 --reference-file workspace/data_dst.mp4 --bitrate \" +str(Bitrate)\n",
        "\n",
        "if Mode == \"result video\":\n",
        "  !python $cmd\n",
        "  if Copy_to_Drive:\n",
        "    !cp /content/workspace/result.mp4 /content/drive/MyDrive/\n",
        "elif Mode == \"result_mask video\":\n",
        "  !python $cmd_mask\n",
        "  if Copy_to_Drive:\n",
        "    !cp /content/workspace/result_mask.mp4 /content/drive/MyDrive/\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "K5LvSv7b5bbb",
        "JuVn21kt40Gw",
        "hqwOlJG4MdLC",
        "tUNVcbujhm00",
        "WTuyUxgdLA13",
        "avAcSL_uvtq_"
      ],
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
